\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}


\begin{document}


<<setup, cache=FALSE,echo=FALSE>>=
library(ggplot2)
library(ggthemes)
data <- read.csv("results/all_results.csv")
@

\title{Improving evolution of service configurations for moving target
defense}

\author{\IEEEauthorblockN{Ernesto Serrano Collado}
\textit{University of Granada}\\
Granada, Spain \\
info@ernesto.es} % Add your name here
\and
\IEEEauthorblockN{Juan J. Merelo-Guerv\'os}
\IEEEauthorblockA{\textit{Dept. of Computer Architecture and Technology} \\
\textit{University of Granada}\\
Granada, Spain \\
jmerelo@ugr.es}

}


\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
The term {\em moving target defense} or MTD describes a series of
techniques that change configuration of an Internet-facing system; in
general, the technique consists in changing visible configuration to
avoid offering a fixed target to service profiling
techniques. Additionally, configurations need to be as secure as
possible and, since change needs to be frequent, to generate also as many as
possible. We introduced previously a proof of concept where a
simplified evolutionary algorithms was used for generating these
configurations. In this paper we improve this algorithm, trying to
adapt it to the specific characteristics of the fitness landscape, and
also looking at finding as many solutions as possible.
\end{abstract}
\begin{IEEEkeywords}

Security, cyberattacks, performance evaluation.
\end{IEEEkeywords}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}


% Some attackers rely on byte patterns: piskozub2019resilience. This
% paper tries to change those patterns by changing the behavior of the
% server. 

% Defense but also detection technique: tian2019moving

% eghtesad2019deep deep reinforcement learning to find the best moment
% for changing configurations.

% POTTEIGER2020102954 integrated defense and control reconfiguration,
% as we do in this paper

% Amplifying randomization as an effective defense kansal2020improving

% Review that includes MTD for combating DDoS attacks with biological
% inspiration. prathyusha2020review

% MTD proved effective against exfiltration techniques shade2020moonraker

% cho2019toward a recent survey, including evolutionary
% algorithms. Also mention the problem of designing a fitness function"

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{State of the art}

% 1. What is moving target defense.
% 2. Bioinspired techniques in cybersecurity.
% 3. Moving target defense as solved by other algorithms, and
% eventually evolutionary (or other) algorithms - JJ

The so-called moving target defense, or MTD, was proposed by the first
time in 2009 \cite{moving-target} as part of an officially sponsored
research program to improve the cyber-capabilities of American
companies and organisms. The NITRD proposed different axes of research
that included models of MTD mechanisms, assessing the problems and
opportunities of randomization of service configuration and profiles,
and creating automatic policies that are able to reduce or eliminate
human intervention in the enforcement of this kind of defense. This
MTD is targeted towards making what is called the attack surface \cite{manadhata2011formal}, that
is, the different mechanisms by which the attacker would be able to
gain access, unpredictable \cite{jajodia2011moving}, and thus either
too expensive or too complex to pursue. An attacker, in this case,
will probably try and pursue different targets, thus reducing security
costs for the defender.

This program was pursued using different kind of techniques, of which
a good survey is made in \cite{Cai2016} and more recently in \cite{lei2018moving,ward2018survey}. These techniques include
bioinspired algorithms; which
% 2.
 have been often used in the area of
cybersecurity; for instance, even before proposing the moving target
defense technique, evolutionary algorithms were applied to intrusion
detection systems \cite{WU20101}. Some authors have proposed using
evolutionary-based optimization techniques to improve detection of SQL
injection attacks and anomalies within HTTP requests
\cite{CHORAS2018179}; other authors \cite{Kozik2014} focus on
detecting SQLIA (SQL Injection Attacks) and XSS (Cross Site Scripting)
at the application layer by modeling HTTP requests with the use of
regular expressions. In general, either by evolution of rules or
programs or by finding the best solution in combinatorial optimization
problems, such as the one we are dealing with in this paper. More
recently, Buji et al. in \cite{buji_genetic_2017} have applied
evolutionary algorithms for a general enhancement of security in real systems.


% 3.
Curiously enough, a bioinspired and ad hoc technique called {\em
  symbiotic embedded machines} (SEM) were proposed by Cui and Stolfo
\cite{cui2011symbiotes} as a methodology for {\em injecting} code into
systems that would behave in a way that would be similar to a
symbiotically-induced immune system. Besides that principled
biological inspiration, SEMs used mutation as a mechanism for avoiding
signature based detection methods and thus become a MTD system. Other early MTD solutions included the use of rotating virtual webservers
\cite{huang2011introducing}, every one with a different attack
surface, to avoid predictability and achieve a variable attack
surface. However, while this was a practical and actionable defense,
no specific technique was proposed to individually configure every
virtual server, proposing instead manual configuration of web servers
(such as nginx and Apache), combined with plug-ins\footnote{It should
  be noted that some of the proposed configurations, such as {\sf nginx} +
  {\tt mod\_rails}, are simply impossible, since {\tt mod\_rails} is an Apache
  plugin, apart from being specifically designed for Ruby on Rails
  applications}. A similar technique, taken to the cloud, was proposed
by Peng et al. \cite{peng2014moving}. In this case, a specific
mechanism that uses different cloud instances and mechanism for moving
virtual machines between them is proposed; still, no specific
mechanism was proposed to establish these configurations.
Although most of the effort is devoted to creating a MTD for servers,
it can also be applied to software defined networks \cite{al2011toward}.

After the early {\em bioinspired} approaches to MTD, explicit
solutions using evolutionary algorithms were conceptually described for the first
time by Crouse and Fulp in \cite{6111663}. This was intended mainly as
a proof of concept, and describes 80 parameters, of which just half
are evolved. The GA minimizes the number of vulnerabilities, but the
study also emphasizes the degree of diversity achieved by successive
generations in the GA, which impact on the diversity needed by the
MTD. Lucas et al. in \cite{lucas2014initial} applied those theoretical
concepts to a framework called EAMT, a Python-based system that uses
evolutionary algorithms to create new configurations, which are then
implemented in a virtual machine and scored using scanning tools such
as Nessus. Later on, John et
al. \cite{john_evolutionary_2014} make a more explicit and practical
use of an evolutionary algorithm, describing a host-level
defense system, that is, one that operates at the level of a single
node in the network, not network-wide, and works on the configuration
of the Apache server, evolving them and evaluating at the parameter
level using the above mentioned CVSS score. These two systems
highlighted the need for, first, a practical way of applying the MTD
to an actual system, to the point of implementing it in a real virtual
machine, and second, the problematic of scoring the generated
configurations. In the next section we will explain our proposed
solutions to these two problems.



MTD can also be applied at a network level. Makanju et al applied
evolutionary algorithms in e defined networks by Champagne et al. in
\cite{Makanju:2017:ECM:3067695.3075604}. In this case the SDN have to
respect the service level agreements, and a fitness function that
takes into account the adaptation of the SDN to the environment. This work was continued by
others in \cite{champagne_genetic_2018}, but in this case the EA
dynamically placed the controller in a network.


Moving target defense has many applications in the field of
cybersecurity. For example, in hardware systems, such as the Morpheus
processor that is able to change its internal configuration every 50
milliseconds to difficult attacks \cite{gallagher_morpheus:_2019}, a
technique like this would have prevented the Spectre vulnerability
suffered by Intel processors that exploited failures in the
speculative execution feature.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Methodology, experimental setup and results}
\label{sec:res}

% 1. Indicate why nginx has been chosen, refer to other papers and what kind of services they chose and why this is new. This must include also a brief explanation of tables 1 and 2 and what the parameters mean, as well as the possible influence on vulnerability they might have.

Considering the huge amount of network services with its multiple
configuration options, it has been decided to limit this project to
alter and optimize the configuration of an HTTP server, specifically
{\sf nginx}. In recent years {\sf nginx} has surpassed Apache as the most used
HTTP server in the world \cite{w3techs_usage_2019}. This service was
chosen over Apache, as was John et al. did in
\cite{john_evolutionary_2014}, since this web server is nowadays much
more popular, and can act as static webserver as well as a reverse
proxy for web services; both configurations will be used and tested.

The last stable version of {\sf nginx} (1.17) has more than 700
configuration directives, which in general constitute the user-facing
attack surface. These parameters, focusing on the ones that will be
evolved, will be analyzed next. The next Subsection \ref{subs:setup}
will outline the setup actually used for running the experiments, and
results will be presented last in Subsection \ref{subs:results}.

\subsection{Description of the attack surface parameters}

There is a huge number parameters that could potentially be chosen for
our experiments so to validate our hypothesis we choose a subset of 9
{\sf nginx} directives (\ref{table:nginx_directives}) and 6 HTTP headers
(\ref{table:http_headers}), all of them related to security
hardening. The subset is extracted from the DISA STIG recommendations
for hardening webservers based in the CVSS score. Most of this values
are defined as Apache HTTP server configuration values but have a
{\sf nginx} equivalent directive.

\begin{table}
\centering
\begin{tabular}{|l|l|c|}
\hline
\textbf{STIG ID} & \textbf{Directive name} 	   & \textbf{Possible values} \\ \hline
V-13730 & worker\_connections            & 512 - 2048 \\ \hline
V-13726 & keepalive\_timeout             & 10 - 120 \\ \hline
V-13732 & disable\_symlinks              & True/False \\ \hline
V-13735 & autoindex                      & True/False \\ \hline
V-13724 & send\_timeout                  & True/False \\ \hline
V-13738 & large\_client\_header\_buffers & 512 - 2048 \\ \hline
V-13736 & client\_max\_body\_size        & 512 - 2048 \\ \hline
V-6724  & server\_tokens                 & True/False \\ \hline
        & gzip                           & True/False \\ \hline
\end{tabular}
\label{table:nginx_directives}
\caption{Selected {\sf nginx} directives list}
\end{table}
%

These are the directives that have been used in this paper; their
equivalent STIG ID is shown in Table
\ref{table:nginx_directives}. \begin{itemize}
\item \texttt{worker\_connections}:
Maximum number of simultaneous connections that can be opened by an {\sf nginx} process.
\item \texttt{keepalive\_timeout}:
Timeout period during which a client connection will remain open on the server side.
\item \texttt{disable\_symlinks}:
Determine if symbolic links can be used when opening files. When activated and some component of the path is a symbolic link the access to that file is denied.
\item \texttt{autoindex}:
When activated it shows the contents of the directories, otherwise it does not show anything.
\item \texttt{send\_timeout}:
The waiting time to transmit a response to the client. The wait time is set only between two successive write operations, not for the transmission of the complete response.
\item \texttt{large\_client\_header\_buffers}:
Maximum number and size of buffers used to read the headers of large requests.

\item
\texttt{client\_max\_body\_size}:
Maximum allowed size of the client request body, specified in the `Content-Length' field of the request header.
\item
\texttt{server\_tokens}:
Enable or disable the broadcast of the {\sf nginx} version on the error pages and in the `Server' response header. It is recommended not giving too extensive information of software versions, but we can cheat the attacker telling wrong server version info.
\item
\texttt{gzip}:
Enable or disable the compression of HTTP responses. This directive doesn't affect directly the security but adds entropy to the different generated configurations.
\end{itemize}

\begin{table}
\centering
\begin{tabular}{|l|l|}
\hline
\textbf{Header name}           & \textbf{Possible values} \\ \hline
X-Frame-Options                & \shortstack[l]{SAMEORIGIN \\ ALLOW-FROM \\ DENY} \\ \hline
X-Powered-By                   & \shortstack[l]{PHP/5.3.3 \\ PHP/5.6.8 \\ PHP/7.2.1 \\ Django2.2 \\ nginx/1.16.0} \\ \hline
X-Content-Type-Options         & nosniff \\ \hline
Server                         & \shortstack[l]{apache \\ caddy \\ nginx/1.16.0} \\ \hline
X-XSS-Protection	           & \shortstack[l]{0 \\ 1 \\ 1; mode=block} \\ \hline
Content-Security-Policy		   & \shortstack[l]{default-src 'self' \\ default-src 'none' \\ default-src 'host *.google.com'} \\ \hline

\end{tabular}
\label{table:http_headers}
\caption{Selected HTTP headers list}
\end{table}
%
The web servers also send a number of headers, which can be configured
also. These are presented next, with possible values represented in
Table \ref{table:http_headers}.
\begin{itemize}
\item
\texttt{X-Frame-Options}:
The `X-Frame-Options' header can be used to indicate whether a browser should be allowed to render an embedded page. Web pages can use it to prevent \textit{clickjacking} attacks, making sure that their content is not embedded in other sites.
\item
\texttt{X-Powered-By}:
The `X-Powered-By 'header is used to specify the software that generated the response. It is recommended not giving too extensive information in this header because can reveal details that can facilitate the task of finding and exploiting security flaws. Doesn't affect directly to the security by itself but adds entropy to the generated configurations.
\item
\texttt{X-Content-Type-Options}:
The HTTP response header `X-Content-Type-Options' indicates that the \textit{MIME} types announced in the `Content-Type' header should not be changed to avoid `MIME type sniffing' attacks.
\item
\texttt{server}:
The `Server 'header contains information about the software used by the server. It is recommended not giving too extensive information of software versions, but we can cheat the attacker telling wrong server version info. Doesn't affect directly to the security but adds entropy to the generated configurations.
\item
\texttt{X-XSS-Protection}:
The HTTP `X-XSS-Protection' response header is a feature that stops pages from loading when they detect reflected cross-site scripting (XSS) attacks.
\item
\texttt{Content-Security-Policy}:
The HTTP `Content-Security-Policy' response header allows web site administrators to control resources the user agent is allowed to load for a given page.
\end{itemize}

\subsection{Experimental setup}
\label{subs:setup}
% 2. Proceed to the evolutionary algorithm used
To write the genetic algorithm we have chosen the Python programming
language due to the availability of the OWASP ZAP API in that
language. In addition, although this project does not require high
performance, several publications indicate a very good performance of
the Python language when working with genetic algorithms
\cite{merelo-guervos_comparison_2016}. The implementation has been
written for this project, and is a simple implementation of a
canonical genetic algorithm; this has been released as free software
together with the rest of the framework. The genetic algorithm works
generating a population of $n$ individuals. Each individual is a
chromosome of 15 gens, each gen referring to the {\sf nginx} directive
or HTTP security headers shown in the previous subsection.

After generating the population we calculate the fitness of that
population using OWASP ZAP, which gives a scalar value with the number of
known vulnerabilities a configuration has. The OWASP ZAP Python API
calling a container with the Docker version of OWASP ZAP; this simulates a
real environment using the {\tt example.com} domain and the generated
configuration. This API will yield the mentioned
scalar value depending on the number of known vulnerabilities found
for that configuration.

Once every individual has been assigned a fitness, we sort the population list
in reverse order to set the better ones at the end of the list and
get the $p$ (pressure) values that we will evolve using mutation and
crossover. This will be repeated  during 15 generations.

For evolving the configuration we have written two different crossover
functions that use either one or two points. We will run the
experiments for each function to find out which
one gives better results \cite{LNCS2439:ID186:pp142}.

Also, we are mutating the population with a chance of 0.4 using two
different mutation methods. One changing random gen with a random
correct value or increasing/decreasing random gen.
After the mutation, we calculate the fitness of the new element, sort
the population and run again the algorithm until no more generations
left.

% 4. Detail the cloud infrastructure that has been created for this.

OWASP ZAP is a heavy-weight process taking a certain amount of time to analyze
each web configuration so we ran the experiments in three AWS EC2 t3.medium
instances all running Ubuntu 18.04 LTS with Docker installed, each
instance has 2 vCPU and 4 GiB of RAM. Each instance runs a different
set of experiments of 16, 32 and 64 population size. To orchestrate
the instances we used a simple Ansible playbook.

For the 16 individuals population size the experiment took an average
of 35 minutes, taking 80 minutes in the 32 individuals population size
and 180 minutes for the 64 individuals population size. This times are
the reason of running each population size in different EC2
instances. The running time of all instances was 266 hours, equivalent
to 11 days of total processing time, having a total cost of \$11.07.

A set of experiments has been carried out with the static site and the juice shop. These have been the parameters that have varied \begin{itemize}
\item Mutation is either {\sf random} or {\sf one}. In the first case, the selected configuration variable is changed by another random value. In the second case, one is added or subtracted from its value.
\item Crossover uses either one or two points.
\item Population goes from 16 to 64 in the case of the static web site, it stops at 32 in the juice shop.
\item The evolutionary algorithm is run for 15 generations.
\end{itemize}

In this case, it's difficult to know in advance what would be the
correct configuration for the evolutionary algorithm, so all these
options have been tested and evaluated to check its influence in the
eventual result. Experiments have been repeated, for each
configuration, 15 times.

\subsection{Experimental results}
\label{subs:results}

%
\begin{figure*}[h!tb]
  \centering
<<results-time,cache=FALSE,echo=FALSE>>=
ggplot(data,aes(x=Population,y=Days,color=Web)) + geom_point()+ theme_tufte()
@
\caption{Scatter plot representing the time, in days, it has taken for
each experiment to be completed. Juice shop experiments were only
completed up to a population of 32.}
\label{fig:time}
\end{figure*}
%
Since the MTD is based on the frequent and unpredictable changing of
configurations, one of the first thing we need to asses is how long it
takes to generate a set of different {\sf nginx} configurations with low
vulnerability. This is represented in Figure \ref{fig:time}, which
plots the duration of all experiments for the static web (Static) and
the juice shop (Juice Shop). Every experiment takes a substantial part
of a day; it goes from 1\% to approximately 12\%, that is, less than
an hour and up to two hours in the case of the static web site. The
time grows linearly with the population, which indicates that it is
dominated by the scoring performed by ZAP, every one of which takes
approximately half a second for the juice shop, a third of a second
for the static web site. This time to generate a configuration
constrains the frequency of change of configurations; on the other
hand, every run generates several viable configurations.

This proves that our method, even using real-life scoring and
deployment methods, is able to generate a good amount of
configurations in a reasonable amount of time.

Of course, we need these configurations to have an acceptable degree
of vulnerabilities. First it should be noted that acceptable ZAP
scores go up to 15; more than that value will not be considered
acceptable. These vulnerabilities captured by ZAP can be dealt with at
a different level, but at any rate, it is always desirable to obtain
as low a level of vulnerabilities as possible. We will analyze each of
the two web payloads in turn, starting with the static web site, which
is the simpler one.

\begin{figure*}[h!tb]
  \centering
  <<results-static,cache=FALSE,echo=FALSE>>=
 data$Crossover <- as.factor(data$Crossover)
data$Population <- as.factor(data$Population)
data.web <- data[data$Web == "Static",]
ggplot(data.web, aes(x=Population,y=Fitness,color=Crossover,shape=Mutation, size=Copies*10,alpha=Days)) + geom_jitter(width = 0.3, height=0)+ theme_tufte()
@
\caption{Scatter plot for OWASP ZAP scores for every experiment using the
  static web site. A ``Copies'' value of 10 indicates that all
  individuals in the population have reached the highest score
  (proportion of the population equal to the highest fitness == 1). "Jitter" is used so that all data points can be visualized. }
\label{fig:zap:static}
\end{figure*}
%
Figure \ref{fig:zap:static}, charts the results for the static
website, representing the ZAP vulnerability score as $y$ axis and the
population as $x$ axis. We need to assess the influence of this
parameter in the final result; but at the same time we need to
evaluate the importance of mutation operators that are being tested,
as well as the relationship between the time employed and the results
obtained.

This figure shows that most experiments result in a vulnerability
score of 11, but in some exceptional cases a vulnerability score of 3
is reached. All these cases have used random mutation and a one-point
crossover, so this might be a combination that, in a few cases, is
able to obtain better results. The transparency of the points, which
is related to time, only seems to depend on the population, that is,
it is equivalent only to the number of evaluations. Better results, in
fact, do no need more time.

It is also interesting to note the actual number of individuals found
in every run, which is inversely proportional to the vulnerability
levels that have been reached: while with ZAP=11 all individuals in
the population have the same value, if the level is equal to 3 a very
small proportion of the population has the same value. This might
indicate the need to run the evolutionary algorithm for longer.

We will examine the next experiment, using the more complicated Juice
Shop, to confirm or dismiss these results. These results are charted
in Figure \ref{fig:zap:juice}.


\begin{figure*}[h!tb]
  \centering
  <<results-juice-shop,cache=FALSE,echo=FALSE>>=
data.juice <- data[data$Web == "Juice Shop",]

ggplot(data.juice, aes(x=Population,y=Fitness,color=Crossover,shape=Mutation, size=Copies*10,alpha=Days))+ geom_jitter(width = 0.3,height=0) +  theme_tufte()
@
\caption{Scatter plot for OWASP ZAP scores for every experiment with the
  Juice Shop site. ``Copies'' is the proportion of the population with
the same ZAP score as the best; 10.0 indicates that the whole
population has the same low vulnerability score (proportion equal to 1). Jittering is using to make the different results visible.}
\label{fig:zap:juice}
\end{figure*}

These results are substantially similar to the previous ones, but there
are differences; for starters, the evaluation takes, as shown above,
more time, so just the population levels of 16 and 32 could be
tested. On the other hand, there are three level of
vulnerabilities, with most experiments resulting in an acceptable
(below 15), but the highest level of 11; a decreasing number of
experiments reach 6 and very few ones get to ZAP = 3.

In the line of the previous results, the best results are obtained
with 1-point crossover and random mutation, although for the medium
level of vulnerability this is not so clear. Besides, when the
additive mutation is used it results in more copies with the same
vulnerability, or fitness.

In general, however, and in both cases, the evolutionary algorithm is
able to find configurations with a low vulnerability level, but there
seems to be a balance between obtaining many results and minimizing
the vulnerability. However, in general, the objectives of this paper
have been reached.

We will discuss these results next.

\section{Conclusions and discussion}
\label{sec:conclusions}

After checking the results we can state that genetic algorithms can
help us to improve the security of a system by generating many
different low-vulnerability configurations for a real, and industry
standard, server, thus being suitable to carry out the moving target
defense along with passive or reactive policies of service
configuration change. An evolutionary algorithm was successfully
applied, allowing configurations to evolve diversely and securely,
although there is a trade-off between them, with lower vulnerability
configurations being generated in less quantity than others with a
slightly higher vulnerability degree. However, low vulnerability
configurations are consistently generated, which means that we could
extract from a population different configurations with different
degrees of vulnerability, contributing even more to the entropy of the
system.

Some vulnerabilities can be caused by a bad configuration or by an
unfortunate combination of configurations that it is difficult for an
administrator to discover manually due to the large number of
parameters and possible combinations. Thanks to a genetic algorithm it
was possible to find more secure configurations. The configurations
were represented as chromosomes and the algorithm took those
chromosomes through a series of selection, crossing and mutation
processes that resulted in even safer configurations than the previous
generation. Using these evolved configurations we achieve the main
objective of this paper, which is transforming our server into a
moving target by changing the configuration with a reasonable
periodicity (with a lower bound of approximately 4-5 hours) using the
configuration with the lowest (or second-lowest) generated by the
algorithm.

These results open new and promising new lines of work. Focusing on
the improvement of {\sf nginx},  more directives as
well as more security-related HTTP headers can be added. This will
expand the search space of the evolutionary algorithm, and this can be
a problem, which is why another possible future work would be to
improve the genetic algorithm avoiding erroneous individuals in the
initial population, generating in this way a safer population, and
besides include some program of benchmark in our fitness function to
know that besides safe, our configuration has a good performance.

However, one of the key issues is speed. The number of evaluations we
are able to use in our evolutionary algorithm is relatively small for
EA standards. We would need to speed up evaluation, and since it
relies on an external tool, the only possible way is to use parallel
evaluation by replicating the docker containers being tested and
having ZAP score them at the same time. A small (4-fold, in the case
of the cloud instance used in our problem) could be achieved this
way. However, much better improvements could be achieved by using
surrogate models \cite{ong2003evolutionary}. This would mean training
some machine learning model that is able to immediately issue a score
for a certain configuration level. These surrogate models could be
combined with real evaluations to give an accurate result, and be able
to reach a good number of evaluations.

Finally, the algorithm itself can be improved, by testing different
types of selection procedures, and tuning its greediness. This is
something that can be done immediately, and will be one of our next steps.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Acknowledgements}

This paper has been supported in part by projects DeepBio (TIN2017-85727-C4-2-P).

\bibliographystyle{IEEEtran}
\bibliography{geneura,moving-target}

\end{document}
