\documentclass[runningheads]{llncs}

%%% Local Variables:
%%% ispell-local-dictionary: "english"
%%% End:
\usepackage[utf8]{inputenc}
\usepackage{booktabs} % For formal tables
\usepackage{graphicx}


\begin{document}


<<setup, cache=FALSE,echo=FALSE>>=
library(ggplot2)
library(ggthemes)
data <- read.csv("results/all_results.csv")
data$Crossover <- as.factor(data$Crossover)
data$Population <- as.factor(data$Population)
data.web <- data[data$Web == "Static",]
data.juice <- data[data$Web == "Juice Shop",]
@

\title{Using evolutionary algorithms for server hardening via the moving target defense technique}

 \author{A\inst{1}
 \and
 B\inst{1}
 \and
 C\inst{1}
 \and
 D\inst{2}
}

\institute{%
   University Z\\
   \email{an@ema.il}
\and
   University Y\\
   \email{another@ema.il}
}

%\authorrunning{Merelo et al.}
%\titlerunning{Using evolutionary algorithms for server hardening via the moving target defense technique}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
The {\em moving target defense} from cyberattacks consists in changing
the profile or signature of certain services in an Internet node so
that an attacker is not able to identify it uniquely, or find specific
angles of attack for it. From an optimization point of view,
generating profiles that change and, besides, optimize security is a
combinatorial optimization problem where different service
configurations are generated and evaluated, seeking the optimum
according to a standard server vulnerability evaluation score. In this
paper we will use an evolutionary algorithm to generate different
server profiles that also minimize the risk of being attacked. Working
on the well-known web server {\tt Nginx}, and using an
industry-standard web configuration, we will prove that this
evolutionary algorithm is able to generate a sufficient amount of
different and secure profiles in time for them to be deployed in the
server. The system has been released as free software, as is the best
practice in security tools. 
\end{abstract}
\keywords{Security, cyberattacks, performance evaluation.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

Many different techniques are used to deflect cyberattacks, that is,
attempts to gain access to certain assets through running code
remotely; these techniques include hardening of services, as well as
deception. {\em Moving target defense} \cite{nitrd,jajodia2011moving}
includes both: the system must be hardened as a point of departure,
but additionally it is going to be changing its attacker-facing profile
and features to make its identification, and thus selection of an
attack surface, more difficult \cite{zhuang2014towards}. This kind of
defense was initially proposed by the Federal Networking and Information Technology Research and
Development (NITRD) Program for the first time in 2009
\cite{moving-target}, and since then it has spawned all kind of
methodologies and software tools to carry it out in practice. The
effectivity of this defense technique is variable and will depend on
the kind of attack \cite{evans2011effectiveness}, but at any rate it
is a valuable addition to the set of tools that are used against
cyberattacks nowadays; besides, it can be applied to several different
services, every one with a different mechanism \cite{Cai2016}, which
makes it a versatile, active defense methodology, appliable at many
levels and in many different ways.

This kind of protection against cybersecurity threats can be implemented by a
proper software configuration without the need to invest in costly
security solutions. In order to measure how optimal a configuration is, an
objective score must be used to measure security or its inverse,
vulnerabilities \cite{yang2012security}: The `Security Technical
Implementation Guides' or STIGs are the configuration standards for
DoD systems provided by the `Defense Information Systems Agency'
(DISA) since 1998. These guides give some recommendations to hardening
the configuration of software systems based on known vulnerabilities
and his impact is classified using the CVSS score. 

The `Common Vulnerability
Scoring System' or CVSS \cite{cvss} is an open standard to measure
computer and network security vulnerabilities. Scores range from 0 to
10, with 10 being the most severe. In order to protect properly a
system, we need to optimize this score so that it gets as close as
possible to zero without compromising any kind of functionality;
however, a 0 score is almost impossible, or at any rate impossible to
measure automatically. Low scores are, thus, desirable as a point of
departure for using additional measures such as the moving target
defense.

Many vulnerabilities can be caused by misconfiguration or an
inadequate combination of parameters. In addition, a given service can
have practically infinite possible configurations, some being less
functional and/or vulnerable than others. 

Also, to create a good mechanism of protection against cyberattacks,
the moving target defense fools the attacker with a continuous change
in the configuration of a given service, so meanwhile an attacker is
fingerprinting your service to discover vulnerabilities, the method or
algorithm applying this kind of defense will have changed the
configuration so the attacker cannot define an attack based on the
known vulnerabilities. In practice, you need to create an additional
policy to change configurations, for instance every time an attack is
detected or periodically, at random moments within a defined
schedule.

% Finding these correct configurations, as well as similar and fully functional configurations, can be a complex task if it is done manually so ideally we would need to find a way to generate such configurations in an automatic way, using some search heuristic. % You need to make paragraphs follow each other - JJ
In practice, the moving target defense implies a method that is able
to yield several low-vulnerability service configurations. In this
paper we are going to focus on the creation of a search method 
that is able to find, in every application, several configurations
with a low vulnerability score. Depending on the (external) policy,
the chief security officer of a network can run (or establish a policy
to run) the search algorithm
once for every scheduled change period, and obtain several candidate
configurations than can then be applied to the service to make it
become the {\em moving} target, as was required.

In this paper we will use a genetic algorithm, which is a search
heuristic that can discover new, secure and diverse configurations by modeling a given
configuration as if they were chromosomes and the different individual
configuration options as if they were genes in that chromosome
\cite{john_evolutionary_2014}. The main idea of genetic algorithms is
that by mutation, crossing and selection of these chromosomes we will
eventually obtain better configurations. Since mutations are random,
they are a source of the diversity we are interested in here.

We need, however, a way to score every individual
chromosome/solution. While CVSS is an abstract way to score security, we first need to
decide on a system for which security is going to be optimized and,
second, on a tool that will be able to automatically compute CVSS or a
vulnerability score related to it. For
the former, we will use an open-source OWASP project called Juice-Shop
\cite{luburic2019utilizing,juice-shop} that consists in a vulnerable
e-commerce platform written in Node.js, Express, and Angular. This is
one of the most typical web application configurations, being more
complex than a simple welcome webpage and more similar to a real
environment; however, we will also include tests for this kind of
simple configuration.

Once the system that is going to be tested is chosen, we need to
quantify the security of a given configuration; for that purpose, we can use tools like
OWASP ZAP \cite{bennetts2013owasp}. OWASP ZAP is an open-source
security analysis tool  for web applications developed by OWASP,
crawls and analyzes a specified site for security vulnerabilities,
yielding a scalar value based on the number of vulnerabilities found
in a site. This score is an alternative to CVSS and STIG, with the
added advantage that it can be assessed automatically via that
tool. There is no direct relationship between CVSS and ZAP score,
although in general a low number in vulnerabilities will result in a
low CVSS score.

Using these two test systems and the automatic ZAP tool as a fitness
score, our moving target defense evolutionary algorithm will rely on
the diversity of each generated configuration to improve the security
of our system. This is based on the entropy of our random generated
and mutated values but this random configuration can be wrong or
vulnerable so we test that configuration and by the genetic algorithm
evolve that configuration to get a good one. 
The same process is be applied to the resulting configurations to
improve the security through generation, but as we more evolve the
configuration we get a much more secure system but we lose
diversity. We need to boost diversity while keeping security high, depending on our
system.

% Introduce here the main points of our paper
% 1. Use of real systems, with a real workload
% 2. use of a real security scoring technique
% 3. Open source, as security systems should be
% 4. Use of industry-standard Nginx.


The rest of the paper is organized as follows: next we present a brief
state of the art in the subject of moving target defense. The
methodology and results are presented in Section \ref{sec:res},
followed by our conclusions.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{State of the art}

% 1. What is moving target defense.
% 2. Bioinspired techniques in cybersecurity.
% 3. Moving target defense as solved by other algorithms, and
% eventually evolutionary (or other) algorithms - JJ

The so-called moving target defense, or MTD, was proposed by the first
time in 2009 \cite{moving-target} as part of an officially sponsored
research program to improve the cyber-capabilities of American
companies and organisms. The NITRD proposed different axes of research
that included models of MTD mechanisms, assessing the problems and
opportunities of randomization of service configuration and profiles,
and creating automatic policies that are able to reduce or eliminate
human intervention in the enforcement of this kind of defense. This
MTD is targeted towards making what is called the attack surface \cite{manadhata2011formal}, that
is, the different mechanisms by which the attacker would be able to
gain access, unpredictable \cite{jajodia2011moving}, and thus either
too expensive or too complex to pursue. An attacker, in this case,
will probably try and pursue different targets, thus reducing security
costs for the defender.

This program was pursued using different kind of techniques, of which
a good survey is made in \ref{Cai2016} and more recently in \cite{lei2018moving,ward2018survey}. These techniques include
bioinspired algorithms; which 
% 2. 
 have been often used in the area of
cybersecurity; for instance, even before proposing the moving target
defense technique, evolutionary algorithms were applied to intrusion
detection systems \cite{WU20101}. Some authors have proposed using
evolutionary-based optimization techniques to improve detection of SQL
injection attacks and anomalies within HTTP requests
\cite{CHORAS2018179}; other authors \cite{Kozik2014} focus on
detecting SQLIA (SQL Injection Attacks) and XSS (Cross Site Scripting)
at the application layer by modeling HTTP requests with the use of
regular expressions. In general, either by evolution of rules or
programs or by finding the best solution in combinatorial optimization
problems, such as the one we are dealing with in this paper. More
recently, Buji et al. in \cite{buji_genetic_2017} have applied
evolutionary algorithms for a general enhancement of security in real systems.


% 3.
Curiosly enough, a bioinspired and ad hoc technique called {\em
  symbiotic embedded machines} (SEM) were proposed by Cui and Stolfo
\cite{cui2011symbiotes} as a methdology for {\em injecting} code into
systems that would behave in a way that would be similar to a
symbiotically-induced immune system. Besides that principled
biological inspiration, SEMs used mutation as a mechanism for avoiding
signature based detection methods and thus become a MTD system. Other early MTD solutions included the use of rotating virtual webservers
\cite{huang2011introducing}, every one with a different attack
surface, to avoid predictability and achieve a variable attack
surface. However, while this was a practical and actionnable defense,
no specific technique was proposed to individually configure every
virtual server, proposing instead manual configuration of web servers
(such as nginx and Apache), combined with plug-ins\footnote{It should
  be noted that some of the proposed configurations, such as Nginx +
  {\tt mod\_rails}, are simply impossible, since {\tt mod\_rails} is an Apache
  plugin, apart from being specifically designed for Ruby on Rails
  applications}. A similar technique, taken to the cloud, was proposed
by Peng et al. \cite{peng2014moving}. In this case, a specific
mechanism that uses different cloud instances and mechanism for moving
virtual machines between them is proposed; still, no specific
mechanism was proposed to establish these configurations. 
Although most of the effort is devoted to creating a MTD for servers,
it can also be applied to software defined networks \cite{al2011toward}.

After the early {\em bioinspired} approaches to MTD, explicit
solutions using evolutionary algorithms were conceptually described for the first
time by Crouse and Fulp in \cite{6111663}. This was intended mainly as
a proof of concept, and describes 80 parameters, of which just half
are evolved. The GA minimizes the number of vulnerabilities, but the
study also emphasizes the degree of diversity achieved by successive
generations in the GA, which impact on the diversity needed by the
MTD. Lucas et al. in \cite{lucas2014initial} applied those theoretical
concepts to a framework called EAMT, a Python-based system that uses
evolutionary algorithms to create new configurations, which are then
implemented in a virtual machine and scored using scanning tools such
as Nessus. Later on, John et
al. \cite{john_evolutionary_2014} make a more explicit and practical
use of an evolutoinary algorithm, describing a host-level
defense system, that is, one that operates at the level of a single
node in the network, not network-wide, and works on the configuration
of the Apache server, evolving them and evaluating at the parameter
level using the above mentioned CVSS score. These two systems
highlighted the need for, first, a practical way of applying the MTD
to an actual system, to the point of implementing it in a real virtual
mchine, and second, the problematic of scoring the generated
configurations. In the next section we will explain our proposed
solutions to these two problems.



MTD can also be aplied at a network level. Makanju et al applied
evolutionary algorithms in e defined networks by Champagne et al. in
\cite{Makanju:2017:ECM:3067695.3075604}. In this case the SDN have to
respect the service level agreements, and a fitness function that
takes into account the adaptation of the SDN to the environment. This work was continued by
others in \cite{champagne_genetic_2018}, but in this case the EA
dynamically placed the controller in a network.


Moving target defense has many applications in the field of
cybersecurity. For example, in hardware systems, such as the Morpheus
processor that is able to change its internal configuration every 50
milliseconds to difficult attacks \cite{gallagher_morpheus:_2019}, a
technique like this would have prevented the Spectre vulnerability
suffered by Intel processors that exploited failures in the
speculative execution feature. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Methodology, experimental setup and results}
\label{sec:res}

% 1. Indicate why nginx has been chosen, refer to other papers and what kind of services they chose and why this is new. This must include also a brief explanation of tables 1 and 2 and what the parameters mean, as well as the possible influence on vulnerability they might have. 

Considering the huge amount of network services with its multiple configuration options, it has been decided to limit this project to alter and optimize the configuration of an HTTP server, specifically Nginx. In recent years Nginx has surpassed Apache as the most used HTTP server in the world \cite{w3techs_usage_2019}.

The last stable version of Nginx (1.17) has more than 700 configuration directives, a huge number to do our experiments so to validate our hypothesis we choose a subset of 9 Nginx directives (\ref{table:nginx_directives}) and 6 HTTP headers (\ref{table:http_headers}), all of them related to security hardening. The subset is extracted from the DISA STIG recommendations for hardening webservers based in the CVSS score. Most of this values are defined as Apache HTTP server configurationv values but have a Nginx equivalent directive.

\subsection{Selected Nginx directives}

\texttt{worker\_connections}:
Maximum number of simultaneous connections that can be opened by an Nginx process.

\texttt{keepalive\_timeout}:
Timeout period during which a client connection will remain open on the server side.

\texttt{disable\_symlinks}:
Determine if symbolic links can be used when opening files. When activated and some component of the path is a symbolic link the access to that file is denied.

\texttt{autoindex}:
When activated it shows the contents of the directories, otherwise it does not show anything.

\texttt{send\_timeout}:
The waiting time to transmit a response to the client. The wait time is set only between two successive write operations, not for the transmission of the complete response.

\texttt{large\_client\_header\_buffers}:
Maximum number and size of buffers used to read the headers of large requests.

\texttt{client\_max\_body\_size}:
Maximum allowed size of the client request body, specified in the `Content-Length' field of the request header.

\texttt{server\_tokens}:
Enable or disable the broadcast of the Nginx version on the error pages and in the `Server' response header. It is recommended not giving too extensive informatión of software versions, but we can cheat the attacker telling wrong server version info.

\texttt{gzip}:
Enable or disable the compression of HTTP responses. This directive doesn't affect directly the security but adds entropy to the different generated configurations.

\subsection{Selected HTTP headers}

\texttt{X-Frame-Options}:
The `X-Frame-Options' header can be used to indicate whether a browser should be allowed to render an embedded page. Web pages can use it to prevent \textit{clickjacking} attacks, making sure that their content is not embedded in other sites.

\texttt{X-Powered-By}:
The `X-Powered-By 'header is used to specify the software that generated the response. It is recommended not giving too extensive information in this header because can reveal details that can facilitate the task of finding and exploiting security flaws. Doesn't affect directly to the security by itself but adds entropy to the generated configurations.

\texttt{X-Content-Type-Options}:
The HTTP response header `X-Content-Type-Options' indicates that the \textit{MIME} types announced in the `Content-Type' header should not be changed to avoid `MIME type sniffing' attacks.

\texttt{server}:
The `Server 'header contains information about the software used by the server. It is recommended not giving too extensive informatión of software versions, but we can cheat the attacker telling wrong server version info. Doesn't affect directly to the security but adds entropy to the generated configurations.

\texttt{X-XSS-Protection}:
The HTTP `X-XSS-Protection' response header is a feature that stops pages from loading when they detect reflected cross-site scripting (XSS) attacks.	     

\texttt{Content-Security-Policy}:
The HTTP `Content-Security-Policy' response header allows web site administrators to control resources the user agent is allowed to load for a given page.

% 2. Proceed to the evolutionary algorithm used
\bigskip
To write the genetic algorithm we choose the Python programming language due to the availability of the OWASP ZAP API in that language. In addition, although this project does not require high performance, several publications indicate a very good performance of the Python language when working with genetic algorithms \cite{merelo-guervos_comparison_2016}.

The genetic algorithm works generating a population of $n$ individuals. Each individual is a chromosome of 15 gens and each gen refers to an Nginx directive or an HTTP security header. 

After generating the population we calculate the fitness of that
population using OWASP ZAP, which gives a scalar value with the number of
known vulnerabilities a configuration has, we sort the population list
in reverser order to set the better ones at the end of the list and
get the $p$ (pressure) values that we will evolve during 15
generations. 

For evolving the configuration we written two different crossover functions. A crossover in one-point and a crossover in two-point functions. We will run the experiments for each function to know which one gives better results \cite{LNCS2439:ID186:pp142}.

Also, we are mutating the population with a chance of 0.4 using two different mutation methods. One changing random gen with a random correct value or increasing/decreasing random gen.
After the mutation, we calculate the fitness of the new element, sort the population and run again the algorithm until no more generations left.

% 3. Small detour devoted to how the fitness function is computed, and also its "cost" in terms of time.

For the fitness function, we are using the OWASP ZAP Python API calling a container with the Docker version of OWASP ZAP simulating a real environment using the example.com domain and the generated configuration. The OWASP ZAP Python API will give the mentioned scalar value depending on the number of known vulnerabilities found that configuration.

% 4. Detail the cloud infrastructure that has been created for this. 

OWASP ZAP is a heavy-weight process taking so much time to analyze each experiment so we ran the experiments in three AWS EC2 t3.medium instances all running Ubuntu 18.04 LTS with Docker installed, each instance has 2 vCPU and 4 GiB of RAM. Each instance runs a different set of experiments of 16, 32 and 64 population size. To orchestrate the instances we used a simple Ansible playbook.

For the 16 individuals population size the experiment took an average
of 35 minutes, taking 80 minutes in the 32 individuals population size
and 180 minutes for the 64 individuals population size. This times are
the reason of running each population size in different EC2
instances. The running time of all instances was 266 hours equivalent
to 11 days of total processing time having a total cost of \$11.07. O

A set of experiments has been carried out with the static site and the juice shop. These have been the parameters that have varied \begin{itemize}
\item Mutation is either {\sf random} or {\sf one}. In the first case, the selected configuration variable is changed by another random value. In the second case, one is added or substracted from its value.
\item Crossover uses either one or two points.
\item Population goes from 16 to 64 in the case of the static web site, it stops at 32 in the juice shop.
\item The evolutionary algorithm is run for 15 generations.
\end{itemize}

In this case, it's difficult to know in advance what would be the
correct configuration for the evolutionary algorithm, so all these
options have been tested and evaluated to check its influence in the
eventual result. Experiments have been repeated, for each
configuration, 15 times.

The experiments are run using these commands

\begin{verbatim}
python3 genetic.py --individuals {16|32|64}
    --crossover-{one|two}-point --[no-]random-mutation
\end{verbatim}


\begin{table}
\centering
\begin{tabular}{|l|l|c|}
\hline
\textbf{STIG ID} & \textbf{Directive name} 	   & \textbf{Possible values} \\ \hline
V-13730 & worker\_connections            & 512 - 2048 \\ \hline
V-13726 & keepalive\_timeout             & 10 - 120 \\ \hline
V-13732 & disable\_symlinks              & True/False \\ \hline
V-13735 & autoindex                      & True/False \\ \hline
V-13724 & send\_timeout                  & True/False \\ \hline
V-13738 & large\_client\_header\_buffers & 512 - 2048 \\ \hline
V-13736 & client\_max\_body\_size        & 512 - 2048 \\ \hline
V-6724  & server\_tokens                 & True/False \\ \hline
        & gzip                           & True/False \\ \hline
\end{tabular}
\label{table:nginx_directives}
\caption{Selected Nginx directives list}
\end{table}

\begin{table}
\centering
\begin{tabular}{|l|l|}
\hline
\textbf{Header name}           & \textbf{Possible values} \\ \hline
X-Frame-Options                & \shortstack[l]{SAMEORIGIN \\ ALLOW-FROM \\ DENY} \\ \hline
X-Powered-By                   & \shortstack[l]{PHP/5.3.3 \\ PHP/5.6.8 \\ PHP/7.2.1 \\ Django2.2 \\ nginx/1.16.0} \\ \hline
X-Content-Type-Options         & nosniff \\ \hline
Server                         & \shortstack[l]{apache \\ caddy \\ nginx/1.16.0} \\ \hline
X-XSS-Protection	           & \shortstack[l]{0 \\ 1 \\ 1; mode=block} \\ \hline
Content-Security-Policy		   & \shortstack[l]{default-src 'self' \\ default-src 'none' \\ default-src 'host *.google.com'} \\ \hline

\end{tabular}
\label{table:http_headers}
\caption{Selected HTTP headers list}
\end{table}
%

The results of the experiments are available with a free license in a
GitHub repository. The results for the static website are represented
in Figure \ref{fig:zap:static}.

%
\begin{figure*}[h!tb]
  \centering
<<results-static,cache=FALSE,echo=FALSE>>=
ggplot(data.web, aes(x=Population,y=Fitness,color=Crossover,shape=Mutation, size=Copies*10,alpha=Days)) + geom_jitter(width = 0.3, height=0)+ theme_tufte()
@
\caption{Scatter plot for OWASP ZAP scores for every experiment using the
  static web site. A ``Copies'' value of 10 indicates that all
  individuals in the population have reached the highest score
  (proportion of the population equal to the highest fitness == 1). "Jitter" is used so that all data points can be visualized. }
\label{fig:zap:static}
\end{figure*}
%
\begin{figure*}[h!tb]
  \centering
<<results-juice-shop,cache=FALSE,echo=FALSE>>=
ggplot(data.juice, aes(x=Population,y=Fitness,color=Crossover,shape=Mutation, size=Copies*10,alpha=Days))+ geom_jitter(width = 0.3,height=0) +  theme_tufte()
@
\caption{Scatter plot for OWASP ZAP scores for every experiment with the
  Juice Shop site. ``Copies'' is the proportion of the population with
the same ZAP score as the best; 10.0 indicates that the whole
population has the same low vulnerability score (proportion equal to 1). Jittering is using to make the different results visible.}
\label{fig:zap:static}
\end{figure*}

\section{Conclusions and discussion}
\label{sec:conclusions}

After checking the results we can state that genetic algorithms can help us to improve the security of a system by modifying the configuration parameters of a server. The algorithm was successfully applied, allowing configurations to evolve diversely and securely.

Some vulnerabilities can be caused by a bad configuration or by an unfortunate combination of configurations that it is difficult for an administrator to discover manually due to the large number of parameters and possible combinations.

Therefore, thanks to a genetic algorithm it was possible to find more secure configurations. The configurations were represented as chromosomes and the algorithm took those chromosomes through a series of selection, crossing and mutation processes that resulted in even safer configurations than the previous generation.

Using these evolved configurations we can transform our server into a moving target by changing the configuration periodically using the ones generated by the algorithm.

Maybe using a genetic algorithm to generate these configurations using such a small number of chromosomes is not the optimal solution, but one of the objectives was to test if genetic algorithms could be used to generate and evolve the configurations and indeed this has been possible.

\subsection{Future Jobs}

This project could be evolved by adding more Nginx directives as well as more security-related HTTP headers. It could also be an improvement try different HTTP servers such as Apache.

Another possible future work would be to improve the genetic algorithm avoiding erroneous individuals in the initial population, generating in this way a safer population, and besides include some program of benchmark in our fitness function to know that besides safe, our configuration has a good performance.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Acknowledgements}

%   This paper has been supported in part by projects DeepBio (TIN2017-85727-C4-2-P) and AMED (co-funded by European Regional Development Fund and the region Normandy).

Acks\\
Taking\\
This much space

\bibliographystyle{splncs04}
\bibliography{geneura,moving-target}

\end{document}
