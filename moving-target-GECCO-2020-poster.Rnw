%\documentclass[sigconf, authordraft]{acmart} -*- mode: Latex -*-
\documentclass[sigconf]{acmart}
\usepackage[utf8]{inputenc}
\usepackage{booktabs} % For formal tables

% Conference
\copyrightyear{2020}
\acmYear{2020}
\setcopyright{rightsretained}
\acmConference[GECCO '20 Companion]{Genetic and Evolutionary Computation Conference Companion}{July 8--12, 2020}{Cancún, Mexico}
\acmBooktitle{Genetic and Evolutionary Computation Conference Companion (GECCO '20 Companion), July 8--12, 2020, Cancún, Mexico}\acmDOI{10.1145/3377929.3390034}
\acmISBN{978-1-4503-7127-8/20/07}

\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}

\begin{document}

<<setup, cache=FALSE,echo=FALSE>>=
suppressPackageStartupMessages({
    library(ggplot2)
    library(ggthemes)
})
@

\title{Moving target defense through evolutionary algorithms}

%%% The submitted version for review should be ANONYMOUS
\author{Ernesto Serrano-Collado}
\affiliation{%
  \institution{University of Granada}
  \city{Granada}
  \country{Spain}
}
\email{info@ernesto.es}

\author{Mario García-Valdez}
\affiliation{%
  \institution{Instituto Tecnológico de Tijuana}
  \city{Tijuana, Baja California}
  \country{Mexico}
}
\email{mario@tectijuana.edu.mx}

\author{Juan-Juli\'an Merelo Guerv\'os}
\affiliation{%
  \institution{University of Granada}
  \city{Granada}
  \country{Spain}}
\email{larst@affiliation.org}

% The default list of authors is too long for headers.
\renewcommand{\shortauthors}{Serrano Collado, García-Valdez, Merelo}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

Moving target defense is a technique for protecting internet-facing
systems via the creation of a {\em variable attack surface}, that is,
a changing profile that, however, is able to provide the same service
to legitimate users. In the case of
internet servers, it can be achieved via the generation of different
configurations that change the service profile, and that can be
included in a policy of restarting services with new configurations
after a random time and with a random frequency. In this paper we will
present a method based on evolutionary algorithms that uses
industry-standard practices to score the vulnerability of a server and
is designed to generate multiple configurations with optimized score
in every run of the algorithm. We make improvements over a previous
version of the method by tuning the evolutionary algorithm with the
challenge of the very costly fitness evaluation that only allows for a
very limited evaluation budget.
\end{abstract}

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10002978.10003006.10011634.10011635</concept_id>
<concept_desc>Security and privacy~Vulnerability scanners</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003752.10003809.10003716.10011136.10011797.10011799</concept_id>
<concept_desc>Theory of computation~Evolutionary algorithms</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10010520.10010521.10010537.10003100</concept_id>
<concept_desc>Computer systems organization~Cloud computing</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Security and privacy~Vulnerability scanners}
\ccsdesc[500]{Theory of computation~Evolutionary algorithms}
\ccsdesc[300]{Computer systems organization~Cloud computing}

\keywords{Security, cyberattacks, performance evaluation, moving
  target defense, evolutionary algorithms, cloud computing, CVSS}

\maketitle


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction, methodology and experimental setup}

Defending targets against cyberattacks includes many different
techniques, like hardening, which  can effectively be formulated the
problem of minimizing vulnerabilities; this will include minimizing
the possibility of an attacker profiling a target, which is the main objective of the so called Moving Target Defense, or MTD \cite{moving-target}. The moving target in this paper will be the {\sf nginx} static web server (like  \cite{john_evolutionary_2014}) and proxy. We are here improving on  the algorithm in \cite{erseco:evostar}, exploring a new  fitness function that takes into
account the severity of the vulnerability.

Optimizing {\sf nginx} involves creating configuration files that will
then be checked for vulnerabilities. The latest versions of this
server have more than 700 configuration
directives, but we
have chosen just fifteen \cite{erseco:evostar}; nine of them affecting the global behavior of the
server, and six affecting the values of specific HTTP headers, which in turn affect how the
browser receiving the information deals with the pages and the
information contained in them. Some
of these directives are security-neutral, and do not actually alter
the vulnerability score; they simply add to overall byte-level diversity, that is, they put the {\em motion} in the{\em moving} target;
some of them, by themselves, will concern the site security.
Not all of these directive actually affect fitness, and thus
vulnerability of the site, and those that do, they create different
kind of vulnerabilities; most of them are about (purported) revelation
of data, but some of them, mainly those related to headers, might
result in some low-level vulnerability.

But first we need to design where to measure those vulnerabilities. As previously \cite{erseco:evostar}, we have used a basic
application with just a few pages and a form with the ZAP application getting the vulnerabilities that affect it. ZAP classifies alerts in four different classes, depending on its
severity: High, Medium, Low and Informational. Of these kind of
vulnerabilities, Informational can be dismissed: Low will be scored with 1, Medium will get 2 as
score, and High will get a 4 score. Overall score needs to be minimized; a ``good'' configuration will be
one that does not have any ``Medium''-scored alert. Every evaluation
is a lengthy process, taking up several seconds.

The evolutionary algorithm also uses an  {\em incremental circular}
mutation, a traditional 2-point crossover that
returns a single chromosome (as opposed to the traditional two),
combining 3 segments, two taken from one parent, one taken from the
other and 2-tournament selection.

The main change in this paper has been the
sorting algorithm used to rank the solutions and select the best
ones: previously, we used the default {\tt sorted} Python function,
which sorts data structures using all the elements of the data
structure sorted; for equal fitness, it will use the chromosome
values. In this paper
we have changed the algorithm to sort only by fitness; when it is the
same, the chromosomes will be kept  in the same random order in which they entered the sort
algorithm. Let's check results next.


\section{Experimental results}
\label{subs:results}

The experiments confirm the result in \cite{erseco:evostar}:
configurations with the lowest vulnerability are already present in
the first generations, so that the evolution
process consists in  {\em filling} the population with
individuals with individuals that have that low vulnerability index
and that, besides, are different enough. The new sorting function,
however, makes the whole last generation usable and sufficiently
different from each other. We represent the average distances in Figure
\ref{fig:md}.
%
\begin{figure}[h!tb]
<<distances, cache=FALSE,echo=FALSE>>=
data.md <- read.csv("results/mutual-distances-averages-entropy.csv")
data.16 = data.md[ data.md$Population == 16, ]
ggplot(data.16,aes(x=Experiment,y=Avg.Distance))+ geom_boxplot() + theme_tufte()
@
\caption{Average mutual distance for individuals in the last
  generation for experiments with population = 16. GECCO labels the ones that use the new sort method, while
  {\tt sorted} uses the same algorithm, but the whole chromosome, not only
the fitness, is sorted; the data labeled "Evostar" uses the previous
fitness function, sorted in the same way.}
  \label{fig:md}
\end{figure}
%
While before last-generation individuals were different, difference
was not so high due to the sorting function. This fitness function
diversifies also distances between them, charted in Figure
\ref{fig:entropy}, which shows the Jenssen-Shannon entropy computed over
the list of pairwise distances.
%
\begin{figure}[h!tb]
<<entropy, cache=FALSE,echo=FALSE>>=
ggplot(data.16,aes(x=Experiment,y=Entropy))+ geom_boxplot() + theme_tufte()
@
\caption{Population-level mutual distance entropy for individuals in the last
  generation for experiments with population = 16 (top). Labels as above, with GECCO tagging the ones we have
  proposed in this paper.}
  \label{fig:entropy}
\end{figure}
%

All the results of experiments, as well as their code and the scripts
needed to generate this data can be found in
\url{https://github.com/JJ/2020-WCCI-variable-attack-surface}, and reused under a free license.

\section{Conclusions and discussion}
\label{sec:conclusions}

The main effect of the new fitness function has been to eliminate
configuration values that created medium-severity vulnerabilities; by making population
selection depend only on fitness and disregard the rest of the
chromosome, parameter-level entropy has received a big boost, which
makes the set of configurations defined by this method much more diverse.

What we have not detected in this work is combinations of
configuration values that can create a vulnerability; in general, it's
specific parameter values what make a certain configuration more
secure or not. This, in turn, implies that any hillclimbing approach,
at least for this specific set of parameters selected, valid in the
hardening part of the optimization. However, using an evolutionary
algorithm is still valid because it is able to find secure
configurations at the same time it generates sets of combinations with
a high entropy, as proved in this paper. In general, tricky
combinations of configuration that would make the system insecure
would not be reasonable. Still, a system with many configuration
parameters, as many as 700, will improve security if it totally or in
part is set automatically using optimization algorithms such as this one.

In this paper we have also found that the baseline secure
configuration has flaws that do not have anything to do with the
configuration of the web server. In the future, we will try to expand the
configuration to the content itself, and also to specific parts of
this content or how it has been generated. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Acknowledgements}

This paper has been supported in part by project DeepBio (TIN2017-85727-C4-2-P).


\bibliographystyle{ACM-Reference-Format}
\bibliography{geneura,moving-target}

\end{document}
