%\documentclass[sigconf, authordraft]{acmart} -*- mode: Latex -*-
\documentclass[sigconf]{acmart}
\usepackage[utf8]{inputenc}
\usepackage{booktabs} % For formal tables

% Conference
\copyrightyear{2020}
\acmYear{2020}
\setcopyright{rightsretained}
\acmConference[GECCO '20 Companion]{Genetic and Evolutionary Computation Conference Companion}{July 8--12, 2020}{Cancún, Mexico}
\acmBooktitle{Genetic and Evolutionary Computation Conference Companion (GECCO '20 Companion), July 8--12, 2020, Cancún, Mexico}\acmDOI{10.1145/3377929.3390034}
\acmISBN{978-1-4503-7127-8/20/07}

\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}

\begin{document}

<<setup, cache=FALSE,echo=FALSE>>=
suppressPackageStartupMessages({
    library(ggplot2)
    library(ggthemes)
})
@

\title{Moving target defense through evolutionary algorithms}

%%% The submitted version for review should be ANONYMOUS
\author{Ernesto Serrano-Collado}
\affiliation{%
  \institution{University of Granada}
  \city{Granada}
  \country{Spain}
}
\email{info@ernesto.es}

\author{Mario García-Valdez}
\affiliation{%
  \institution{Instituto Tecnológico de Tijuana}
  \city{Tijuana, Baja California}
  \country{Mexico}
}
\email{mario@tectijuana.edu.mx}

\author{Juan-Juli\'an Merelo Guerv\'os}
\affiliation{%
  \institution{University of Granada}
  \city{Granada}
  \country{Spain}}
\email{larst@affiliation.org}

% The default list of authors is too long for headers.
\renewcommand{\shortauthors}{B. Trovato et al.}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

Moving target defense is a technique for protecting internet-facing
systems via the creation of a {\em variable attack surface}, that is,
a changing profile that, however, is able to provide the same service
to letitimate users. In the case of
internet servers, it can be achieved via the generation of different
configurations that change the service profile, and that can be
included in a policy of restarting services with new configurations
after a random time and with a random frequency. In this paper we will
present a method based on evolutionary algorithms that uses
industry-standard practices to score the vulnerability of a server and
is designed to generate multiple configurations with optimized score
in every run of the algorithm. We make improvements over a previous
version of the method by tuning the evolutionary algorithm with the
challenge of the very costly fitness evaluation that only allows for a
very limited evaluation budget.
\end{abstract}

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10002978.10003006.10011634.10011635</concept_id>
<concept_desc>Security and privacy~Vulnerability scanners</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003752.10003809.10003716.10011136.10011797.10011799</concept_id>
<concept_desc>Theory of computation~Evolutionary algorithms</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10010520.10010521.10010537.10003100</concept_id>
<concept_desc>Computer systems organization~Cloud computing</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Security and privacy~Vulnerability scanners}
\ccsdesc[500]{Theory of computation~Evolutionary algorithms}
\ccsdesc[300]{Computer systems organization~Cloud computing}

\keywords{Security, cyberattacks, performance evaluation, moving
  target defense, evolutionary algorithms, cloud computing, CVSS}

\maketitle


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction, methodology and experimental setup}

Defending targets against cyberattacks includes many different
techniques, like hardening, which  can effectively be formulated as an optimization one: minimizing vulnerabilities; this will include minimizing the possibility of profiling a target, which is the main objective of the so called Moving Target Defense, or MTD \cite{moving-target}. The moving target in this paper will be the {\sf nginx} static web server (like  \cite{john_evolutionary_2014}) and proxy. We are here improving on  the algorithm in \cite{erseco:evostar}, exploring a new  fitness function that takes into
account the severity of the vulnerability. {\sf nginx} is a  popular static web server, inverse proxy, API gateway
and load balancer. Its latest versions have more than 700 configuration
directives, but we
have chosen just fifteen \cite{erseco:evostar}; nine of them affecting the global behavior of the
server, and six affecting the values of specific HTTP headers, which in turn affect how the
browser receiving the information deals with the pages and the
information contained in them. Some
of these directives are security-neutral, and do not actually alter
the security score, they simply add to overall byte-level diversity, that is, they put the {\em motion} in the{\em moving} target;
some of them, by themselves, will concern the site security.
Not all of these directive actually affect fitness, and thus
vulnerability of the site, and those that do, they create different
kind of vulnerabilities; most of them are about (purported) revelation
of data, but some of them, mainly those related to headers, might
result in some low-level vulnerability.

But first we need to design where to measure those vulnerabilities. As previously \cite{erseco:evostar}, we have used a basic
application with just a few pages and a form with the ZAP application getting the vulnerabilities that affect it. ZAP classifies alerts in four different classes, depending on its
severity: High, Medium, Low and Informational. Of these kind of
vulnerabilities, Informational can be dismissed: Low will be scored with 1, Medium will get 2 as
score, and High will get a 4 score. Overall score needs to be minimized; a ``good'' configuration will be
one that does not have any ``Medium''-scored alert. Every evaluation
is a lengthy process, taking up several seconds.

The evolutionary algorithm also uses an  {\em incremental circular}
mutation, a traditional 2-point crossover that
returns a single chromosome (as opposed to the traditional two),
combining 3 segments, two taken from one parent, one taken from the
other and 2-tournament selection.

The main change in this paper has been the 
sorting algorithm used to rank the solutions and select the best
ones: previously, we used the default {\tt sorted} Python function,
which sorts data structures using all the elements of the data
structure sorted; for equal fitness, it will use the chromosome
values. In this paper
we have changed the algorithm to only use the fitness; when it is the
same, the chromosomes will be kept  in the same random order in which they entered the sort
algorithm. Let's check results next.


\section{Experimental results}
\label{subs:results}

First we will test what are the results with the new fitness function,
as well as the rest of the incremental improvements we made to the
implementation of the evolutionary moving target defense method.
%
 introduced in this paper, besides the new fitness
function, is the fact that there are no invalid configurations
generated, since all invalid test values have been eliminated from the
chromosome. The previous experiments showed that eventually those
values were eliminated from the population, but they were still
present, adding invalid configurations to the pool of evaluations we
cannot afford. 
As in our previous paper, the best fitness obtained is already present
in an individual in the first generation, so that the evolution
process consists in eventually {\em filling} the population with
individuals with this, highest, fitness. The main difference from
\cite{erseco:evostar} to this paper is that, in this case,
there will be no chromosome in the last generation with medium
vulnerabilities: all of them, thanks to the new fitness designed, have
low vulnerability, as well as "information-level" vulnerabilities
which are not really considered in this new fitness. As was the case
before, 100\% of all chromosomes share this low vulnerability score.

But the real improvement lays in the use of the new sorting function
to select chromosomes. We represent the average distances in Figure
\ref{fig:md}.
%
\begin{figure}[h!tb]
<<distances, cache=FALSE,echo=FALSE>>=
data.md <- read.csv("results/mutual-distances-averages-entropy.csv")
data.16 = data.md[ data.md$Population == 16, ]
data.32 = data.md[ data.md$Population == 32, ]
ggplot(data.16,aes(x=Experiment,y=Avg.Distance))+ geom_boxplot() + theme_tufte()
@
\caption{Average mutual distance for individuals in the last
  generation for experiments with population = 16. GECCO labels the ones that use the new sort method, while
  "Sorted" uses the same algorithm, but the whole chromosome, not only
the fitness, is sorted; the data labeled "Evostar" uses the previous
fitness function, sorted in the same way.}
  \label{fig:md}
\end{figure}
%
The figures clearly show that the per-file average mutual distances
between different individuals have increased, thanks to the simple
change of using a better sorting routine for selection. Average
distances were very similar before that change, and didn't depend on
the type of fitness. All that could be affirmed about the previous set
of solutions was that they were pairwise different; now we can also
affirm that there's a good average distance between them; this
distance is not normalized, however, and could be dominated by a few
components whose range is bigger; this is why we have also computed
the entropy of these distances, charted in Figure
\ref{fig:entropy}. This is the Jenssen-Shannon entropy computed over
the list of pairwise distances.
%
\begin{figure}[h!tb]
<<entropy, cache=FALSE,echo=FALSE>>=
ggplot(data.16,aes(x=Experiment,y=Entropy))+ geom_boxplot() + theme_tufte()
@
\caption{Population-level mutual distance entropy for individuals in the last
  generation for experiments with population = 16 (top). Labels as above, with GECCO tagging the ones we have
  proposed in this paper.}
  \label{fig:entropy}
\end{figure}
%
Again, entropy is much higher in the new experiment, with this
indicating that how far away a component is going to be from others
has an element of surprise, which is what we are looking for in the
MTD methodology. Still, we need to look at the component-level
entropy, that is, the degree of surprise of a particular element in
the chromosome: see Figure \ref{fig:component:entropy}
%
\begin{figure}[h!tb]
<<component.entropy, cache=FALSE,echo=FALSE>>=
entropy.initial <- read.csv("results/component-entropy-evostar.csv")
entropy.new <- read.csv("results/component-entropy-sorted.csv")
entropy.unsorted <- read.csv("results/component-entropy-gecco.csv")

entropy.initial$Experiment <- "Evostar"
entropy.new$Experiment <- "Sorted"
entropy.unsorted$Experiment <- "GECCO"

entropy.data <- rbind(entropy.initial, entropy.new, entropy.unsorted)

entropy.data$Population <- substr( entropy.data$File, 16, 17 )

ggplot( entropy.data[entropy.data$Population==16,], aes(x=Experiment,y=Entropy)) + geom_boxplot()+ theme_tufte()
@
\caption{Component-level entropy for individuals in the last
  generation for experiments with population = 16 (top). Labels as above, with GECCO tagging the ones we have
  proposed in this paper.}
  \label{fig:component:entropy}
\end{figure}
%
Once again, added entropy for all components is much higher;
component-wise, there might not be much variation, mainly in those
components that have few values and/or have only some values that
result in low or no vulnerability; the added value, however, is that
this new version of the evolutionary moving target defense framework
is able to generate low-vulnerability, high-diversity, sets of
configurations that can then be used successively in setting
configuration for {\sf nginx} servers, changing them with high frequency.

All the results of experiments, as well as their code and the scripts
needed to generate this data can be found in
% \url{https://github.com/JJ/2020-WCCI-variable-attack-surface}
\url{https://github.com/anonymous/repo}, and can
be reused with a free license.

\section{Conclusions and discussion}
\label{sec:conclusions}

% Write conclusions here
In this paper we have presented an improved evolutionary algorithm
that generates diverse configurations for the {\sf nginx} server, as a
showcase of service-level (and, to a certain point, network-level)
moving target defense. This work has been the result of progressive
code-level refinement of the evolutionary algorithm, as well as an
improvement in the selection strategy and the fitness function.

The main effect of changing the fitness function has been to eliminate
configuration values that created medium-severity vulnerabilities; in
our previous paper \cite{erseco:cec} all vulnerabilities received the
same score, and there could be cases where these stayed in the final
population. But the biggest impact on entropy of the final
configurations has been achieved by changing the sorting
algorithm. While in \cite{erseco:cec} final configurations were
different, parameter-level entropy was small; by making population
selection depend only on fitness and disregard the rest of the
chromosome, parameter-level entropy has received a big boost, which
makes the set of configurations defined by this method better. This
move has had the side effect of keeping diversity high, by introducing
a random element (the order in which individuals were drawn originally
from the population) in the selection procedure, something that was
missing when chromosomes with the same fitness were sorted in
lexicographical order.

What we have not detected in this work is combinations of
configuration values that can create a vulnerability; in general, it's
specific parameter values what make a certain configuration more
secure or not. This, in turn, implies that any hillclimbing approach,
at least for this specific set of parameters selected, valid in the
hardening part of the optimization. However, using an evolutionary
algorithm is still valid because it is able to find secure
configurations at the same time it generates sets of combinations with
a high entropy, as proved in this paper. In general, tricky
combinations of configuration that would make the system insecure
would not be reasonable. Still, a system with many configuration
parameters, as many as 700, will improve security if it totally or in
part is set automatically using optimization algorithms such as this one.

% Future lines of work.
The main challenge of this kind of problem and solving it with
evolutionary algorithms is still evaluation speed, so in the immediate future our focus will be on analyzing the different
parts of the experimental setup so that we can iron out all problems,
and also attain whatever speed ups can be attained with it, so that
evaluation can be faster; for instance, we should try and look at a
way of evaluating several configurations in parallel, and maybe make
the algorithm asynchronous so that it does not have to wait for a full
generation before performing its operations. This is one of the main drawbacks of the algorithm right now,
and although part of it is inherent (it still has to try every single
page of a site), we could try to achieve faster
evaluation by using a different web for generating the configuration
and for deploying the configuration. Using the actual web we are
testing for evolving
configurations can be incredibly time-consuming; the use of surrogates
would speed up evolution, either by creating surrogates of the web
itself or by trying to make parts of the evaluation via surrogates
obtained a deep learning algorithm which, besides, should give us some
insight on the problems created by different features and what predict
insecure configurations just by looking at them, without the need to
put up an actual web site.

In this paper we have also found that the baseline secure
configuration has flaws that do not have anything to do with the
configuration of the web server. We will try to expand the
configuration to the content itself, and also to specific parts of
this content or how it has been generated. We can also extend
evolutionary MTD to other services, whose configurations can be
evolved alongside the web server for more variable attack surfaces, or
even change the web server so that the configuration is even more
difficult to detect. Addinfg multi-objective evolution so that we
improve performance alongside security is also something we intend to
pursue in the future.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Acknowledgements}

This paper has been supported in part by project DeepBio (TIN2017-85727-C4-2-P).


\bibliographystyle{ACM-Reference-Format}
\bibliography{geneura,moving-target}

\end{document}
